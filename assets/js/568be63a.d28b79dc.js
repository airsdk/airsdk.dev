"use strict";(self.webpackChunkairsdk_dev=self.webpackChunkairsdk_dev||[]).push([[54797],{20660:(e,n,t)=>{t.d(n,{A:()=>o});const o=t.p+"assets/images/so_soundVisualizer-654b26300e53f8208e5972b858b591a3.png"},28453:(e,n,t)=>{t.d(n,{R:()=>i,x:()=>a});var o=t(96540);const r={},s=o.createContext(r);function i(e){const n=o.useContext(s);return o.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:i(e.components),o.createElement(s.Provider,{value:n},e.children)}},39436:(e,n,t)=>{t.d(n,{A:()=>o});const o=t.p+"assets/images/so_computeSpectrum_popup-bf67112dcdce2e2e483c6c39e95dade9.png"},44302:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>d,contentTitle:()=>a,default:()=>l,frontMatter:()=>i,metadata:()=>o,toc:()=>c});const o=JSON.parse('{"id":"development/rich-media-content/working-with-sound/accessing-raw-sound-data","title":"Accessing raw sound data","description":"The SoundMixer.computeSpectrum() method lets an application read the raw sound","source":"@site/docs/development/rich-media-content/working-with-sound/accessing-raw-sound-data.md","sourceDirName":"development/rich-media-content/working-with-sound","slug":"/development/rich-media-content/working-with-sound/accessing-raw-sound-data","permalink":"/docs/development/rich-media-content/working-with-sound/accessing-raw-sound-data","draft":false,"unlisted":false,"editUrl":"https://github.com/airsdk/airsdk.dev/edit/main/docs/development/rich-media-content/working-with-sound/accessing-raw-sound-data.md","tags":[],"version":"current","sidebarPosition":11,"frontMatter":{"sidebar_position":11},"sidebar":"mainSidebar","previous":{"title":"Working with sound metadata","permalink":"/docs/development/rich-media-content/working-with-sound/working-with-sound-metadata"},"next":{"title":"Capturing sound input","permalink":"/docs/development/rich-media-content/working-with-sound/capturing-sound-input"}}');var r=t(74848),s=t(28453);const i={sidebar_position:11},a="Accessing raw sound data",d={},c=[{value:"Building a simple sound visualizer",id:"building-a-simple-sound-visualizer",level:2}];function h(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",header:"header",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"accessing-raw-sound-data",children:"Accessing raw sound data"})}),"\n",(0,r.jsxs)(n.p,{children:["The ",(0,r.jsx)(n.code,{children:"SoundMixer.computeSpectrum()"})," method lets an application read the raw sound\ndata for the waveform that is currently being played. If more than one\nSoundChannel object is currently playing the ",(0,r.jsx)(n.code,{children:"SoundMixer.computeSpectrum()"}),"\nmethod shows the combined sound data of every SoundChannel object mixed\ntogether."]}),"\n",(0,r.jsx)(n.p,{children:"The sound data is returned as a ByteArray object containing 512 bytes of data,\neach of which contains a floating point value between -1 and 1. These values\nrepresent the amplitude of the points in the sound waveform being played. The\nvalues are delivered in two groups of 256, the first group for the left stereo\nchannel and the second group for the right stereo channel."}),"\n",(0,r.jsxs)(n.p,{children:["The ",(0,r.jsx)(n.code,{children:"SoundMixer.computeSpectrum()"})," method returns frequency spectrum data rather\nthan waveform data if the ",(0,r.jsx)(n.code,{children:"FFTMode"})," parameter is set to ",(0,r.jsx)(n.code,{children:"true"}),". The frequency\nspectrum shows amplitude arranged by sound frequency, from lowest frequency to\nhighest. A Fast Fourier Transform (FFT) is used to convert the waveform data\ninto frequency spectrum data. The resulting frequency spectrum values range from\n0 to roughly 1.414 (the square root of 2)."]}),"\n",(0,r.jsxs)(n.p,{children:["The following diagram compares the data returned from the ",(0,r.jsx)(n.code,{children:"computeSpectrum()"}),"\nmethod when the ",(0,r.jsx)(n.code,{children:"FFTMode"})," parameter is set to ",(0,r.jsx)(n.code,{children:"true"})," and when it is set to\n",(0,r.jsx)(n.code,{children:"false"}),". The sound whose data was used for this diagram contains a loud bass\nsound in the left channel and a drum hit sound in the right channel."]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:t(39436).A+"",width:"607",height:"477"})}),"\n",(0,r.jsx)(n.p,{children:"Values returned by the SoundMixer.computeSpectrum() method"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"A."})," fftMode=true"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"B."})," fftMode=false"]}),"\n",(0,r.jsxs)(n.p,{children:["The ",(0,r.jsx)(n.code,{children:"computeSpectrum()"})," method can also return data that has been resampled at a\nlower bit rate. Generally, this results in smoother waveform data or frequency\ndata at the expense of detail. The ",(0,r.jsx)(n.code,{children:"stretchFactor"})," parameter controls the rate\nat which the ",(0,r.jsx)(n.code,{children:"computeSpectrum()"})," method data is sampled. When the\n",(0,r.jsx)(n.code,{children:"stretchFactor"})," parameter is set to 0, the default, the sound data is sampled at\na rate of 44.1 kHz. The rate is halved at each successive value of the\nstretchFactor parameter, so a value of 1 specifies a rate of 22.05 kHz, a value\nof 2 specifies a rate of 11.025 kHz, and so on. The ",(0,r.jsx)(n.code,{children:"computeSpectrum()"})," method\nstill returns 256 bytes per stereo channel when a higher ",(0,r.jsx)(n.code,{children:"stretchFactor"})," value\nis used."]}),"\n",(0,r.jsxs)(n.p,{children:["The ",(0,r.jsx)(n.code,{children:"SoundMixer.computeSpectrum()"})," method has some limitations:"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["Because sound data from a microphone or from RTMP streams do not pass through\nthe global SoundMixer object, the ",(0,r.jsx)(n.code,{children:"SoundMixer.computeSpectrum()"})," method will\nnot return data from those sources."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["If one or more of the sounds being played come from sources outside the\ncurrent content sandbox, security restrictions will cause the\n",(0,r.jsx)(n.code,{children:"SoundMixer.computeSpectrum()"})," method to throw an error. For more detail about\nthe security limitations of the ",(0,r.jsx)(n.code,{children:"SoundMixer.computeSpectrum()"})," method please\nsee\n",(0,r.jsx)(n.a,{href:"/docs/development/rich-media-content/working-with-sound/security-considerations-when-loading-and-playing-sounds",children:"Security considerations when loading and playing sounds"}),"\nand\n",(0,r.jsx)(n.a,{href:"/docs/development/security/accessing-loaded-media-as-data",children:"Accessing loaded media as data"}),"."]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"However, in an AIR application, content in the application security sandbox\n(content installed with the AIR application) are not restricted by these\nsecurity limitations."}),"\n",(0,r.jsx)(n.h2,{id:"building-a-simple-sound-visualizer",children:"Building a simple sound visualizer"}),"\n",(0,r.jsxs)(n.p,{children:["The following example uses the ",(0,r.jsx)(n.code,{children:"SoundMixer.computeSpectrum()"})," method to show a\nchart of the sound waveform that animates with each frame:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:'import flash.display.Graphics;\nimport flash.events.Event;\nimport flash.media.Sound;\nimport flash.media.SoundChannel;\nimport flash.media.SoundMixer;\nimport flash.net.URLRequest;\n\nconst PLOT_HEIGHT:int = 200;\nconst CHANNEL_LENGTH:int = 256;\n\nvar snd:Sound = new Sound();\nvar req:URLRequest = new URLRequest("bigSound.mp3");\nsnd.load(req);\n\nvar channel:SoundChannel;\nchannel = snd.play();\naddEventListener(Event.ENTER_FRAME, onEnterFrame);\nsnd.addEventListener(Event.SOUND_COMPLETE, onPlaybackComplete);\n\nvar bytes:ByteArray = new ByteArray();\n\nfunction onEnterFrame(event:Event):void\n{\n\tSoundMixer.computeSpectrum(bytes, false, 0);\n\n\tvar g:Graphics = this.graphics;\n\n\tg.clear();\n\tg.lineStyle(0, 0x6600CC);\n\tg.beginFill(0x6600CC);\n\tg.moveTo(0, PLOT_HEIGHT);\n\n\tvar n:Number = 0;\n\n\t// left channel\n\tfor (var i:int = 0; i < CHANNEL_LENGTH; i++)\n\t{\n\t\tn = (bytes.readFloat() * PLOT_HEIGHT);\n\t\tg.lineTo(i * 2, PLOT_HEIGHT - n);\n\t}\n\tg.lineTo(CHANNEL_LENGTH * 2, PLOT_HEIGHT);\n\tg.endFill();\n\n\t// right channel\n\tg.lineStyle(0, 0xCC0066);\n\tg.beginFill(0xCC0066, 0.5);\n\tg.moveTo(CHANNEL_LENGTH * 2, PLOT_HEIGHT);\n\n\tfor (i = CHANNEL_LENGTH; i > 0; i--)\n\t{\n\t\tn = (bytes.readFloat() * PLOT_HEIGHT);\n\t\tg.lineTo(i * 2, PLOT_HEIGHT - n);\n\t}\n\tg.lineTo(0, PLOT_HEIGHT);\n\tg.endFill();\n}\n\nfunction onPlaybackComplete(event:Event)\n{\n\tremoveEventListener(Event.ENTER_FRAME, onEnterFrame);\n}\n'})}),"\n",(0,r.jsxs)(n.p,{children:["This example first loads and plays a sound file and then listens for the\n",(0,r.jsx)(n.code,{children:"Event.ENTER_FRAME"})," event which will trigger the ",(0,r.jsx)(n.code,{children:"onEnterFrame()"})," method while\nthe sound plays. The ",(0,r.jsx)(n.code,{children:"onEnterFrame()"})," method starts by calling the\n",(0,r.jsx)(n.code,{children:"SoundMixer.computeSpectrum()"})," method, which stores the sound wave data in the\n",(0,r.jsx)(n.code,{children:"bytes"})," ByteArray object."]}),"\n",(0,r.jsxs)(n.p,{children:["The sound waveform is plotted using the vector drawing API. A ",(0,r.jsx)(n.code,{children:"for"})," loop cycles\nthrough the first 256 data values, representing the left stereo channel, and\ndraws a line from each point to the next using the ",(0,r.jsx)(n.code,{children:"Graphics.lineTo()"})," method. A\nsecond ",(0,r.jsx)(n.code,{children:"for"})," loop cycles through the next set of 256 values, plotting them in\nreverse order this time, from right to left. The resulting waveform plots can\nproduce an interesting mirror-image effect, as shown in the following image."]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:t(20660).A+"",width:"470",height:"334"})})]})}function l(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(h,{...e})}):h(e)}}}]);