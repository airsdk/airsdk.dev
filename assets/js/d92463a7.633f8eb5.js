"use strict";(self.webpackChunkairsdk_dev=self.webpackChunkairsdk_dev||[]).push([[81145],{28453:(e,n,t)=>{t.d(n,{R:()=>d,x:()=>r});var a=t(96540);const o={},i=a.createContext(o);function d(e){const n=a.useContext(i);return a.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:d(e.components),a.createElement(i.Provider,{value:n},e.children)}},73184:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>s,contentTitle:()=>r,default:()=>h,frontMatter:()=>d,metadata:()=>a,toc:()=>l});const a=JSON.parse('{"id":"development/rich-media-content/working-with-sound/working-with-dynamically-generated-audio","title":"Working with dynamically generated audio","description":"Note: The ability to dynamically generate audio is available starting with Flash","source":"@site/docs/development/rich-media-content/working-with-sound/working-with-dynamically-generated-audio.md","sourceDirName":"development/rich-media-content/working-with-sound","slug":"/development/rich-media-content/working-with-sound/working-with-dynamically-generated-audio","permalink":"/docs/development/rich-media-content/working-with-sound/working-with-dynamically-generated-audio","draft":false,"unlisted":false,"editUrl":"https://github.com/airsdk/airsdk.dev/edit/main/docs/development/rich-media-content/working-with-sound/working-with-dynamically-generated-audio.md","tags":[],"version":"current","sidebarPosition":6,"frontMatter":{"sidebar_position":6},"sidebar":"mainSidebar","previous":{"title":"Working with streaming sound files","permalink":"/docs/development/rich-media-content/working-with-sound/working-with-streaming-sound-files"},"next":{"title":"Playing sounds","permalink":"/docs/development/rich-media-content/working-with-sound/playing-sounds"}}');var o=t(74848),i=t(28453);const d={sidebar_position:6},r="Working with dynamically generated audio",s={},l=[{value:"Modifying sound from mp3 data",id:"modifying-sound-from-mp3-data",level:2},{value:"Limitations on generated sounds",id:"limitations-on-generated-sounds",level:2}];function c(e){const n={code:"code",h1:"h1",h2:"h2",header:"header",p:"p",pre:"pre",...(0,i.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"working-with-dynamically-generated-audio",children:"Working with dynamically generated audio"})}),"\n",(0,o.jsx)(n.p,{children:"Note: The ability to dynamically generate audio is available starting with Flash\nPlayer 10 and Adobe AIR 1.5."}),"\n",(0,o.jsxs)(n.p,{children:["Instead of loading or streaming an existing sound, you can generate audio data\ndynamically. You can generate audio data when you assign an event listener for\nthe ",(0,o.jsx)(n.code,{children:"sampleData"})," event of a Sound object. (The ",(0,o.jsx)(n.code,{children:"sampleData"})," event is defined in\nthe SampleDataEvent class in the flash.events package.) In this environment, the\nSound object doesn't load sound data from a file. Instead, it acts as a socket\nfor sound data that is being streamed to it through the use of the function you\nassign to this event."]}),"\n",(0,o.jsxs)(n.p,{children:["When you add a ",(0,o.jsx)(n.code,{children:"sampleData"})," event listener to a Sound object, the object\nperiodically requests data to add to the sound buffer. This buffer contains data\nfor the Sound object to play. When you call the ",(0,o.jsx)(n.code,{children:"play()"})," method of the Sound\nobject, it dispatches the ",(0,o.jsx)(n.code,{children:"sampleData"})," event when requesting new sound data.\n(This is true only when the Sound object has not loaded mp3 data from a file.)"]}),"\n",(0,o.jsxs)(n.p,{children:["The SampleDataEvent object includes a ",(0,o.jsx)(n.code,{children:"data"})," property. In your event listener,\nyou write ByteArray objects to this ",(0,o.jsx)(n.code,{children:"data"})," object. The byte arrays you write to\nthis object add to buffered sound data that the Sound object plays. The byte\narray in the buffer is a stream of floating-point values from -1 to 1. Each\nfloating-point value represents the amplitude of one channel (left or right) of\na sound sample. Sound is sampled at 44,100 samples per second. Each sample\ncontains a left and right channel, interleaved as floating-point data in the\nbyte array."]}),"\n",(0,o.jsxs)(n.p,{children:["In your handler function, you use the ",(0,o.jsx)(n.code,{children:"ByteArray.writeFloat()"})," method to write\nto the ",(0,o.jsx)(n.code,{children:"data"})," property of the ",(0,o.jsx)(n.code,{children:"sampleData"})," event. For example, the following\ncode generates a sine wave:"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"var mySound:Sound = new Sound();\nmySound.addEventListener(SampleDataEvent.SAMPLE_DATA, sineWaveGenerator);\nmySound.play();\nfunction sineWaveGenerator(event:SampleDataEvent):void\n{\n\tfor (var i:int = 0; i < 8192; i++)\n\t{\n\t\tvar n:Number = Math.sin((i + event.position) / Math.PI / 4);\n\t\tevent.data.writeFloat(n);\n\t\tevent.data.writeFloat(n);\n\t}\n}\n"})}),"\n",(0,o.jsxs)(n.p,{children:["When you call ",(0,o.jsx)(n.code,{children:"Sound.play()"}),", the application starts calling your event handler,\nrequesting sound sample data. The application continues to send events as the\nsound plays back until you stop providing data, or until you call\n",(0,o.jsx)(n.code,{children:"SoundChannel.stop()"}),"."]}),"\n",(0,o.jsx)(n.p,{children:"The latency of the event varies from platform to platform, and could change in\nfuture versions of Flash Player and AIR. Do not depend on a specific latency;\ncalculate it instead. To calculate the latency, use the following formula:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"(SampleDataEvent.position / 44.1) - SoundChannelObject.position\n"})}),"\n",(0,o.jsxs)(n.p,{children:["Provide from 2048 through 8192 samples to the ",(0,o.jsx)(n.code,{children:"data"})," property of the\nSampleDataEvent object (for each call to the event listener). For best\nperformance, provide as many samples as possible (up to 8192). The fewer samples\nyou provide, the more likely it is that clicks and pops will occur during\nplayback. This behavior can differ on various platforms and can occur in various\nsituations\u2014for example, when resizing the browser. Code that works on one\nplatform when you provide only 2048 sample might not work as well when run on a\ndifferent platform. If you require the lowest latency possible, consider making\nthe amount of data user-selectable."]}),"\n",(0,o.jsxs)(n.p,{children:["If you provide fewer than 2048 samples (per call to the ",(0,o.jsx)(n.code,{children:"sampleData"})," event\nlistener), the application stops after playing the remaining samples. The\nSoundChannel object then dispatches a SoundComplete event."]}),"\n",(0,o.jsx)(n.h2,{id:"modifying-sound-from-mp3-data",children:"Modifying sound from mp3 data"}),"\n",(0,o.jsxs)(n.p,{children:["You use the ",(0,o.jsx)(n.code,{children:"Sound.extract()"})," method to extract data from a Sound object. You\ncan use (and modify) that data to write to the dynamic stream of another Sound\nobject for playback. For example, the following code uses the bytes of a loaded\nMP3 file and passes them through a filter function, ",(0,o.jsx)(n.code,{children:"upOctave()"}),":"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:'var mySound:Sound = new Sound();\nvar sourceSnd:Sound = new Sound();\nvar urlReq:URLRequest = new URLRequest("test.mp3");\nsourceSnd.load(urlReq);\nsourceSnd.addEventListener(Event.COMPLETE, loaded);\nfunction loaded(event:Event):void\n{\n\tmySound.addEventListener(SampleDataEvent.SAMPLE_DATA, processSound);\n\tmySound.play();\n}\nfunction processSound(event:SampleDataEvent):void\n{\n'})}),"\n",(0,o.jsxs)(n.p,{children:["var bytes",":ByteArray"," = new ByteArray();\nsourceSnd.extract(bytes, 8192);\nevent.data.writeBytes(upOctave(bytes));"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"}\nfunction upOctave(bytes:ByteArray):ByteArray\n{\n\tvar returnBytes:ByteArray = new ByteArray();\n\tbytes.position = 0;\n\twhile(bytes.bytesAvailable > 0)\n\t{\n\t\treturnBytes.writeFloat(bytes.readFloat());\n\t\treturnBytes.writeFloat(bytes.readFloat());\n\t\tif (bytes.bytesAvailable > 0)\n\t\t{\n\t\t\tbytes.position += 8;\n\t\t}\n\t}\n\treturn returnBytes;\n}\n"})}),"\n",(0,o.jsx)(n.h2,{id:"limitations-on-generated-sounds",children:"Limitations on generated sounds"}),"\n",(0,o.jsxs)(n.p,{children:["When you use a ",(0,o.jsx)(n.code,{children:"sampleData"})," event listener with a Sound object, the only other\nSound methods that are enabled are ",(0,o.jsx)(n.code,{children:"Sound.extract()"})," and ",(0,o.jsx)(n.code,{children:"Sound.play()"}),". Calling\nany other methods or properties results in an exception. All methods and\nproperties of the SoundChannel object are still enabled."]})]})}function h(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(c,{...e})}):c(e)}}}]);