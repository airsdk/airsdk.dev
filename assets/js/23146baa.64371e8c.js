"use strict";(globalThis.webpackChunkairsdk_dev=globalThis.webpackChunkairsdk_dev||[]).push([[48943],{11600:(n,e,o)=>{o.r(e),o.d(e,{assets:()=>d,contentTitle:()=>r,default:()=>h,frontMatter:()=>a,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"development/rich-media-content/working-with-sound/basics-of-working-with-sound","title":"Basics of working with sound","description":"Computers can capture and encode digital audio\u2014computer representation of sound","source":"@site/docs/development/rich-media-content/working-with-sound/basics-of-working-with-sound.md","sourceDirName":"development/rich-media-content/working-with-sound","slug":"/development/rich-media-content/working-with-sound/basics-of-working-with-sound","permalink":"/docs/development/rich-media-content/working-with-sound/basics-of-working-with-sound","draft":false,"unlisted":false,"editUrl":"https://github.com/airsdk/airsdk.dev/edit/main/docs/development/rich-media-content/working-with-sound/basics-of-working-with-sound.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1},"sidebar":"mainSidebar","previous":{"title":"Working with sound","permalink":"/docs/development/rich-media-content/working-with-sound/"},"next":{"title":"Understanding the sound architecture","permalink":"/docs/development/rich-media-content/working-with-sound/understanding-the-sound-architecture"}}');var i=o(74848),s=o(28453);const a={sidebar_position:1},r="Basics of working with sound",d={},c=[{value:"Important concepts and terms",id:"important-concepts-and-terms",level:4}];function l(n){const e={a:"a",br:"br",h1:"h1",h4:"h4",header:"header",li:"li",p:"p",ul:"ul",...(0,s.R)(),...n.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(e.header,{children:(0,i.jsx)(e.h1,{id:"basics-of-working-with-sound",children:"Basics of working with sound"})}),"\n",(0,i.jsx)(e.p,{children:"Computers can capture and encode digital audio\u2014computer representation of sound\ninformation\u2014and can store it and retrieve it to play back over speakers. You can\nplay back sound using either Adobe\xae Flash\xae Player or Adobe\xae AIR\u2122 and\nActionScript."}),"\n",(0,i.jsx)(e.p,{children:"When sound data is converted to digital form, it has various characteristics,\nsuch as the sound's volume and whether it is stereo or mono sound. When you play\nback a sound in ActionScript, you can adjust these characteristics as well\u2014make\nthe sound louder, or make it seem to be coming from a certain direction, for\ninstance."}),"\n",(0,i.jsx)(e.p,{children:"Before you can control a sound in ActionScript, you need to have the sound\ninformation loaded into Flash Player or AIR. There are five ways you can get\naudio data into Flash Player or AIR so that you can work with it using\nActionScript."}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsxs)(e.li,{children:["\n",(0,i.jsx)(e.p,{children:"Load an external sound file such as an mp3 file into the SWF."}),"\n"]}),"\n",(0,i.jsxs)(e.li,{children:["\n",(0,i.jsx)(e.p,{children:"Embed the sound information into the SWF file directly when it's being\ncreated."}),"\n"]}),"\n",(0,i.jsxs)(e.li,{children:["\n",(0,i.jsx)(e.p,{children:"Capture audio from a microphone attached to a user's computer."}),"\n"]}),"\n",(0,i.jsxs)(e.li,{children:["\n",(0,i.jsx)(e.p,{children:"Stream audio from a server."}),"\n"]}),"\n",(0,i.jsxs)(e.li,{children:["\n",(0,i.jsx)(e.p,{children:"Dynamically generate and play audio."}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(e.p,{children:"When you load sound data from an external sound file, you can begin playing back\nthe start of the sound file while the rest of the sound data is still loading."}),"\n",(0,i.jsx)(e.p,{children:"Although there are various sound file formats used to encode digital audio,\nActionScript 3.0, Flash Player and AIR support sound files that are stored in\nthe mp3 format. They cannot directly load or play sound files in other formats\nlike WAV or AIFF."}),"\n",(0,i.jsx)(e.p,{children:"While you're working with sound in ActionScript, you'll likely work with several\nclasses from the flash.media package. The Sound class is the class you use to\nget access to audio information by loading a sound file or assigning a function\nto an event that samples sound data and then starting playback. Once you start\nplaying a sound, Flash Player and AIR give you access to a SoundChannel object.\nSince an audio file that you've loaded may only be one of several sounds that\nyou play on a user's computer, each individual sound that's playing uses its own\nSoundChannel object; the combined output of all the SoundChannel objects mixed\ntogether is what actually plays over the computer's speakers. You use this\nSoundChannel instance to control properties of the sound and to stop its\nplayback. Finally, if you want to control the combined audio, the SoundMixer\nclass gives you control over the mixed output."}),"\n",(0,i.jsxs)(e.p,{children:["You can also use several other classes to perform more specific tasks when\nyou're working with sound in ActionScript; for more information on all the\nsound-related classes, see\n",(0,i.jsx)(e.a,{href:"/docs/development/rich-media-content/working-with-sound/understanding-the-sound-architecture",children:"Understanding the sound architecture"}),"."]}),"\n",(0,i.jsx)(e.h4,{id:"important-concepts-and-terms",children:"Important concepts and terms"}),"\n",(0,i.jsx)(e.p,{children:"The following reference list contains important terms that you may encounter:"}),"\n",(0,i.jsxs)(e.p,{children:["Amplitude",(0,i.jsx)(e.br,{}),"\n","The distance of a point on the sound waveform from the zero or equilibrium line."]}),"\n",(0,i.jsxs)(e.p,{children:["Bit rate",(0,i.jsx)(e.br,{}),"\n","The amount of data that is encoded or streamed for each second of a sound file.\nFor mp3 files, the bit rate is usually stated in terms of thousands of bits per\nsecond (kbps). A higher bit rate generally means a higher quality sound wave."]}),"\n",(0,i.jsxs)(e.p,{children:["Buffering",(0,i.jsx)(e.br,{}),"\n","The receiving and storing of sound data before it is played back."]}),"\n",(0,i.jsxs)(e.p,{children:["mp3",(0,i.jsx)(e.br,{}),"\n","MPEG-1 Audio Layer 3, or mp3, is a popular sound compression format."]}),"\n",(0,i.jsxs)(e.p,{children:["Panning",(0,i.jsx)(e.br,{}),"\n","The positioning of an audio signal between the left and right channels in a\nstereo soundfield."]}),"\n",(0,i.jsxs)(e.p,{children:["Peak",(0,i.jsx)(e.br,{}),"\n","The highest point in a waveform."]}),"\n",(0,i.jsxs)(e.p,{children:["Sampling rate",(0,i.jsx)(e.br,{}),"\n","Defines the number of samples per second taken from an analog audio signal to\nmake a digital signal. The sampling rate of standard compact disc audio is 44.1\nkHz or 44,100 samples per second."]}),"\n",(0,i.jsxs)(e.p,{children:["Streaming",(0,i.jsx)(e.br,{}),"\n","The process of playing the early portions of a sound file or video file while\nlater portions of that file are still being loaded from a server."]}),"\n",(0,i.jsxs)(e.p,{children:["Volume",(0,i.jsx)(e.br,{}),"\n","The loudness of a sound."]}),"\n",(0,i.jsxs)(e.p,{children:["Waveform",(0,i.jsx)(e.br,{}),"\n","The shape of a graph of the varying amplitudes of a sound signal over time."]})]})}function h(n={}){const{wrapper:e}={...(0,s.R)(),...n.components};return e?(0,i.jsx)(e,{...n,children:(0,i.jsx)(l,{...n})}):l(n)}},28453:(n,e,o)=>{o.d(e,{R:()=>a,x:()=>r});var t=o(96540);const i={},s=t.createContext(i);function a(n){const e=t.useContext(s);return t.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function r(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(i):n.components||i:a(n.components),t.createElement(s.Provider,{value:e},n.children)}}}]);