"use strict";(globalThis.webpackChunkairsdk_dev=globalThis.webpackChunkairsdk_dev||[]).push([[34538],{28453:(e,n,t)=>{t.d(n,{R:()=>a,x:()=>d});var o=t(96540);const s={},i=o.createContext(s);function a(e){const n=o.useContext(i);return o.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function d(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:a(e.components),o.createElement(i.Provider,{value:n},e.children)}},93659:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>r,contentTitle:()=>d,default:()=>h,frontMatter:()=>a,metadata:()=>o,toc:()=>c});const o=JSON.parse('{"id":"development/rich-media-content/working-with-sound/understanding-the-sound-architecture","title":"Understanding the sound architecture","description":"Your applications can load sound data from five main sources:","source":"@site/docs/development/rich-media-content/working-with-sound/understanding-the-sound-architecture.md","sourceDirName":"development/rich-media-content/working-with-sound","slug":"/development/rich-media-content/working-with-sound/understanding-the-sound-architecture","permalink":"/docs/development/rich-media-content/working-with-sound/understanding-the-sound-architecture","draft":false,"unlisted":false,"editUrl":"https://github.com/airsdk/airsdk.dev/edit/main/docs/development/rich-media-content/working-with-sound/understanding-the-sound-architecture.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2},"sidebar":"mainSidebar","previous":{"title":"Basics of working with sound","permalink":"/docs/development/rich-media-content/working-with-sound/basics-of-working-with-sound"},"next":{"title":"Loading external sound files","permalink":"/docs/development/rich-media-content/working-with-sound/loading-external-sound-files"}}');var s=t(74848),i=t(28453);const a={sidebar_position:2},d="Understanding the sound architecture",r={},c=[];function l(e){const n={a:"a",code:"code",em:"em",h1:"h1",header:"header",li:"li",p:"p",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,i.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"understanding-the-sound-architecture",children:"Understanding the sound architecture"})}),"\n",(0,s.jsx)(n.p,{children:"Your applications can load sound data from five main sources:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"External sound files loaded at run time"}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Sound resources embedded within the application's SWF file"}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Sound data from a microphone attached to the user's system"}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Sound data streamed from a remote media server, such as Flash Media Server"}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["Sound data being generated dynamically through the use of the ",(0,s.jsx)(n.code,{children:"sampleData"}),"\nevent handler"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Sound data can be fully loaded before it is played back, or it can be streamed,\nmeaning that it is played back while it is still loading."}),"\n",(0,s.jsxs)(n.p,{children:["The ActionScript 3.0 sound classes support sound files that are stored in the\nmp3 format. They cannot directly load or play sound files in other formats, such\nas WAV or AIFF. However, starting with Flash Player 9.0.115.0, AAC audio files\ncan be loaded and played using the NetStream class. This is the same technique\nas is used for loading and playing video content. For more information on this\ntechnique, see ",(0,s.jsx)(n.a,{href:"/docs/development/rich-media-content/working-with-video/",children:"Working with video"}),"."]}),"\n",(0,s.jsxs)(n.p,{children:['Using Adobe Flash Professional, you can import WAV or AIFF sound files and then\nembed them into your application\'s SWF files in the mp3 format. The Flash\nAuthoring tool also lets you compress embedded sound files to reduce their file\nsize, though this size reduction comes at the expense of sound quality. For more\ninformation see "Importing Sounds" in ',(0,s.jsx)(n.em,{children:"Using Flash"}),"."]}),"\n",(0,s.jsx)(n.p,{children:"The ActionScript 3.0 sound architecture makes use of the following classes in\nthe flash.media package."}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Class"}),(0,s.jsx)(n.th,{children:"Description"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"flash.media.Sound"}),(0,s.jsx)(n.td,{children:"The Sound class handles the loading of sound, manages basic sound properties, and starts a sound playing."})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"flash.media.SoundChannel"}),(0,s.jsx)(n.td,{children:"When an application plays a Sound object, a new SoundChannel object is created to control the playback. The SoundChannel object controls the volume of both the left and right playback channels of the sound. Each sound that plays has its own SoundChannel object."})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"flash.media.SoundLoaderContext"}),(0,s.jsxs)(n.td,{children:["The SoundLoaderContext class specifies how many seconds of buffering to use when loading a sound, and whether Flash Player or AIR looks for a policy file from the server when loading a file. A SoundLoaderContext object is used as a parameter to the ",(0,s.jsx)(n.code,{children:"Sound.load()"})," method."]})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"flash.media.SoundMixer"}),(0,s.jsx)(n.td,{children:"The SoundMixer class controls playback and security properties that pertain to all sounds in an application. In effect, multiple sound channels are mixed through a common SoundMixer object, so property values in the SoundMixer object will affect all SoundChannel objects that are currently playing."})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"flash.media.SoundTransform"}),(0,s.jsx)(n.td,{children:"The SoundTransform class contains values that control sound volume and panning. A SoundTransform object can be applied to an individual SoundChannel object, to the global SoundMixer object, or to a Microphone object, among others."})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"flash.media.ID3Info"}),(0,s.jsx)(n.td,{children:"An ID3Info object contains properties that represent ID3 metadata information that is often stored in mp3 sound files."})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"flash.media.Microphone"}),(0,s.jsx)(n.td,{children:"The Microphone class represents a microphone or other sound input device attached to the user's computer. Audio input from a microphone can be routed to local speakers or sent to a remote server. The Microphone object controls the gain, sampling rate, and other characteristics of its own sound stream."})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"flash.media.AudioPlaybackMode"}),(0,s.jsxs)(n.td,{children:["The AudioPlaybackMode class defines constants for the ",(0,s.jsx)(n.code,{children:"audioPlaybackMode"})," property of the SoundMixer class."]})]})]})]}),"\n",(0,s.jsx)(n.p,{children:"Each sound that is loaded and played needs its own instance of the Sound class\nand the SoundChannel class. The output from multiple SoundChannel instances is\nthen mixed together by the global SoundMixer class during playback,"}),"\n",(0,s.jsx)(n.p,{children:"The Sound, SoundChannel, and SoundMixer classes are not used for sound data\nobtained from a microphone or from a streaming media server like Flash Media\nServer."})]})}function h(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(l,{...e})}):l(e)}}}]);